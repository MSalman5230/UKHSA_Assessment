{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UK Health Security Agency (UKHSA)\n",
    "Description : Your task is to write a reproducible ETL pipeline to process a CSV data file of your choice using python code (this could include activities, but not limited to data manipulation, data validation and error handling etc.) that could be deployed on either an on-premise SQL server or within a cloud environment such as Azure/AWS.\n",
    "Your objective is to create an ETL pipeline, considering access such as security, scalability and maintainability. We are interested in seeing how you apply your code writing ability and service knowledge to meet these goals effectively.\n",
    "\n",
    "### Note: As the Question did not specify how the data will be used, I am gonna approach it as this data will be loaded to SQL server for analytical and Machine learning purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset downloaded from https://www.kaggle.com/datasets/prasad22/healthcare-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "For deployment, managed Airflow from Azure Data Factory will be used,\n",
    "This notebook explains the steps I took, but this ETL pipelines will be deployed in Airflow Azure Data Factory.\n",
    "Why:\n",
    "1. UKHSA already uses Azure\n",
    "2. Security: Only the pipeline owner has access to the data and who has right Azure Policy have access to data\n",
    "3. Scalability:Azure Managed Airflow automatically scales Apache Airflow nodes when required based on range specification (min, max)\n",
    "4. Mintainability: Airflow DAGs are easily maintainable, Has WebUI to manage task, and to drill down on logs for any error. With Github its also reliably with version control.\n",
    "\n",
    "Deployment Procedure:\n",
    "1. Have a DAGs repo in Github.\n",
    "2. push newly created DAG. Code review and Merge\n",
    "3. In Azure DF, create a new airflow instance link it to this repo. and install dependencies as required.\n",
    "\n",
    "Test DataPipeline, Depending on the Pipelines many test can be used pytest, or for have a local environment. In case of this pipeline most error can occur if format of csv changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"healthcare_dataset_.csv\", index_col=False) # for cloud premise this would be path to S3 storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Medical Condition</th>\n",
       "      <th>Date of Admission</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Hospital</th>\n",
       "      <th>Insurance Provider</th>\n",
       "      <th>Billing Amount</th>\n",
       "      <th>Room Number</th>\n",
       "      <th>Admission Type</th>\n",
       "      <th>Discharge Date</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Test Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tiffany Ramirez</td>\n",
       "      <td>81</td>\n",
       "      <td>Female</td>\n",
       "      <td>O-</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>17/11/22</td>\n",
       "      <td>Patrick Parker</td>\n",
       "      <td>Wallace-Hamilton</td>\n",
       "      <td>Medicare 37490.98336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>Elective</td>\n",
       "      <td>01-12-22</td>\n",
       "      <td>Aspirin</td>\n",
       "      <td>Inconclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruben Burns</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>O+</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>01.06.23</td>\n",
       "      <td>Diane Jackson</td>\n",
       "      <td>Burke, Griffin and Cooper</td>\n",
       "      <td>UnitedHealthcare 47304.06485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>15-06-23</td>\n",
       "      <td>Lipitor</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chad Byrd</td>\n",
       "      <td>61</td>\n",
       "      <td>Male</td>\n",
       "      <td>B-</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>09-01-19</td>\n",
       "      <td>Paul Baker</td>\n",
       "      <td>Walton LLC</td>\n",
       "      <td>Medicare 36874.897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>292</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>08-02-19</td>\n",
       "      <td>Lipitor</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antonio Frederick</td>\n",
       "      <td>49</td>\n",
       "      <td>Male</td>\n",
       "      <td>B-</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>02-05-20</td>\n",
       "      <td>Brian Chandler</td>\n",
       "      <td>Garcia Ltd</td>\n",
       "      <td>Medicare 23303.32209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>03-05-20</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mrs. Brandy Flowers</td>\n",
       "      <td>51</td>\n",
       "      <td>Male</td>\n",
       "      <td>O-</td>\n",
       "      <td>Arthritis</td>\n",
       "      <td>09-07-21</td>\n",
       "      <td>Dustin Griffin</td>\n",
       "      <td>Jones, Brown and Murray</td>\n",
       "      <td>UnitedHealthcare 18086.34418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>477</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>02-08-21</td>\n",
       "      <td>Paracetamol</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name  Age  Gender Blood Type Medical Condition  \\\n",
       "0      Tiffany Ramirez   81  Female         O-          Diabetes   \n",
       "1          Ruben Burns   35    Male         O+            Asthma   \n",
       "2            Chad Byrd   61    Male         B-           Obesity   \n",
       "3    Antonio Frederick   49    Male         B-            Asthma   \n",
       "4  Mrs. Brandy Flowers   51    Male         O-         Arthritis   \n",
       "\n",
       "  Date of Admission          Doctor                   Hospital  \\\n",
       "0          17/11/22  Patrick Parker           Wallace-Hamilton   \n",
       "1          01.06.23   Diane Jackson  Burke, Griffin and Cooper   \n",
       "2          09-01-19      Paul Baker                 Walton LLC   \n",
       "3          02-05-20  Brian Chandler                 Garcia Ltd   \n",
       "4          09-07-21  Dustin Griffin    Jones, Brown and Murray   \n",
       "\n",
       "             Insurance Provider  Billing Amount  Room Number Admission Type  \\\n",
       "0          Medicare 37490.98336             NaN          146       Elective   \n",
       "1  UnitedHealthcare 47304.06485             NaN          404      Emergency   \n",
       "2            Medicare 36874.897             NaN          292      Emergency   \n",
       "3          Medicare 23303.32209             NaN          480         Urgent   \n",
       "4  UnitedHealthcare 18086.34418             NaN          477         Urgent   \n",
       "\n",
       "  Discharge Date   Medication  Test Results  \n",
       "0       01-12-22      Aspirin  Inconclusive  \n",
       "1       15-06-23      Lipitor        Normal  \n",
       "2       08-02-19      Lipitor        Normal  \n",
       "3       03-05-20   Penicillin      Abnormal  \n",
       "4       02-08-21  Paracetamol        Normal  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10006 entries, 0 to 10005\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Name                10006 non-null  object \n",
      " 1   Age                 10006 non-null  int64  \n",
      " 2   Gender              10006 non-null  object \n",
      " 3   Blood Type          10006 non-null  object \n",
      " 4   Medical Condition   10006 non-null  object \n",
      " 5   Date of Admission   10006 non-null  object \n",
      " 6   Doctor              10006 non-null  object \n",
      " 7   Hospital            10006 non-null  object \n",
      " 8   Insurance Provider  10006 non-null  object \n",
      " 9   Billing Amount      0 non-null      float64\n",
      " 10  Room Number         10006 non-null  int64  \n",
      " 11  Admission Type      10006 non-null  object \n",
      " 12  Discharge Date      10006 non-null  object \n",
      " 13  Medication          10006 non-null  object \n",
      " 14  Test Results        10006 non-null  object \n",
      "dtypes: float64(1), int64(2), object(12)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate 5\n",
      "Empty values: 0\n",
      "NaN values: 10006\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate\",df.duplicated().sum())\n",
    "\n",
    "empty_values = df[df == ''].count()\n",
    "print(\"Empty values:\",empty_values.sum())\n",
    "\n",
    "nan_values = df.isnull().sum()\n",
    "print(\"NaN values:\",nan_values.sum())\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify wrong formats in Data and other discrepancy \n",
    "- \"Date of Admission\" Col have date in 3 formats using / . -\n",
    "- \"Insurance Provider\" Col has \"Billing Amount\" Col data added to it and  \"Billing Amount\" col is empty \n",
    "- there are few dups\n",
    "- We will also drop \"Name\" as its is irrelevant for analytical purpose. and for maintaining user privacy. Also if there was a column where uses has opt out of any use of his/her data then we would drop entire row for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of Admission'] = pd.to_datetime(df['Date of Admission'], format='%d/%m/%y', errors='coerce').fillna(\n",
    "                    pd.to_datetime(df['Date of Admission'], format='%d.%m.%y', errors='coerce')).fillna(\n",
    "                    pd.to_datetime(df['Date of Admission'], format='%d-%m-%y', errors='coerce'))\n",
    "\n",
    "df['Discharge Date'] = pd.to_datetime(df['Discharge Date'], format='%d/%m/%y', errors='coerce').fillna(\n",
    "                    pd.to_datetime(df['Discharge Date'], format='%d.%m.%y', errors='coerce')).fillna(\n",
    "                    pd.to_datetime(df['Discharge Date'], format='%d-%m-%y', errors='coerce'))\n",
    "\n",
    "df.drop(columns=['Name'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    # Extract numerical value from the end of the Insurance Provider\n",
    "    numerical_value =  row['Insurance Provider'].split()[-1]\n",
    "    \n",
    "    #Check if number extracted is numerical\n",
    "    if numerical_value.replace(\".\",\"\").isnumeric():\n",
    "        df.at[index, 'Billing Amount'] = float(numerical_value)\n",
    "        df.at[index, 'Insurance Provider'] = row['Insurance Provider'].replace(numerical_value,\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "As this is be used for Analytical and ML use, I will be creating new column Stay Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stay Length days'] = (df['Discharge Date'] - df['Date of Admission']).dt.days\n",
    "\n",
    "#Here we can drop the 'Discharge Date' as we can calculate Discharge Date by using Date of Admission + Stay Length\n",
    "df.drop(columns=['Discharge Date'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to lowercase and replace spaces with underscores\n",
    "df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
    "#df['entry id'] = np.arange(0, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10001 entries, 0 to 10000\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   age                 10001 non-null  int64         \n",
      " 1   gender              10001 non-null  object        \n",
      " 2   blood_type          10001 non-null  object        \n",
      " 3   medical_condition   10001 non-null  object        \n",
      " 4   date_of_admission   10001 non-null  datetime64[ns]\n",
      " 5   doctor              10001 non-null  object        \n",
      " 6   hospital            10001 non-null  object        \n",
      " 7   insurance_provider  10001 non-null  object        \n",
      " 8   billing_amount      10001 non-null  float64       \n",
      " 9   room_number         10001 non-null  int64         \n",
      " 10  admission_type      10001 non-null  object        \n",
      " 11  medication          10001 non-null  object        \n",
      " 12  test_results        10001 non-null  object        \n",
      " 13  stay_length_days    10001 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(9)\n",
      "memory usage: 1.4+ MB\n",
      "Empty values: 0\n",
      "NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "empty_values = df[df == ''].count()\n",
    "print(\"Empty values:\",empty_values.sum())\n",
    "\n",
    "nan_values = df.isnull().sum()\n",
    "print(\"NaN values:\",nan_values.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values = df[[\"age\",\"gender\",\"date_of_admission\"  ,\"doctor\" ,\"hospital\" ,\"billing_amount\",\"admission_type\"  ] ].isnull().sum()    \n",
    "if nan_values.sum()>0:\n",
    "    print(\"Key Data missing\")\n",
    "\n",
    "# This condition will be added to the DAGs to check if any key data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "def get_postgres_connection():   \n",
    "# Set up connection parameters\n",
    "    host = '192.168.11.3' # os.environ['PG_HOST']\n",
    "    database = 'huruhuru' \n",
    "    user = 'huruhuru' \n",
    "    password = 'abc123'\n",
    "\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        connection = psycopg2.connect(\n",
    "            host=host,\n",
    "            database=database,\n",
    "            user=user,\n",
    "            password=password\n",
    "        )\n",
    "        print(\"Postgres connected\")\n",
    "        return connection\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while connecting to PostgreSQL\", error,\"type\",type(error))\n",
    "        raise error\n",
    "\n",
    "\n",
    "def postgres_insert(conn, df, table):\n",
    "    \"\"\"\n",
    "    Using psycopg2.extras.execute_values() to insert the dataframe\n",
    "    \"\"\"\n",
    "    # Create a list of tupples from the dataframe values\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL quert to execute\n",
    "    query  = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples) # execute_values is sed as this is better performance than all other methods https://naysan.ca/2020/05/09/pandas-to-postgresql-using-psycopg2-bulk-insert-performance-benchmark/\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"execute_values() done\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postgres connected\n"
     ]
    }
   ],
   "source": [
    "pg_conn=get_postgres_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_insert(pg_conn,df,\"patient_records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Schema for loading the data\n",
    "``` sql\n",
    "CREATE TABLE patient_records (\n",
    "    age INTEGER NOT NULL,\n",
    "    gender VARCHAR(10) NOT NULL,\n",
    "    date_of_admission TIMESTAMP NOT NULL,\n",
    "    blood_type VARCHAR(5),\n",
    "    medical_condition VARCHAR(255),\n",
    "    doctor VARCHAR(255) NOT NULL,\n",
    "    hospital VARCHAR(255) NOT NULL,\n",
    "    insurance_provider VARCHAR(255),\n",
    "    billing_amount NUMERIC(12, 2) NOT NULL,\n",
    "    room_number INTEGER,\n",
    "    admission_type VARCHAR(50) NOT NULL,\n",
    "    medication VARCHAR(255),\n",
    "    test_results TEXT,\n",
    "    stay_length_days INTEGER,\n",
    "    entry_id SERIAL PRIMARY KEY\n",
    ");\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
